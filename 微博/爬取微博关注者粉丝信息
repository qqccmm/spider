from urllib.parse import urlencode  
import requests, csv
# https://m.weibo.cn/profile/{0}.format(uid) url构造里面找最为靠前的uid参数
# https://m.weibo.cn/p/index?containerid=231051_-_followers_-_5692692520 关注者信息 id中uid需要寻找，其他参数均为固定。
# https://m.weibo.cn/p/index?containerid=231051_-_fans_-_5692692520 粉丝信息
    
def get_page(page):  
    uid = 3167305545 #网页构造变换的关键
    base_url = 'https://m.weibo.cn/api/container/getIndex?'  
    headers = {  
    'Host': 'm.weibo.cn',   
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36',  
    'X-Requested-With': 'XMLHttpRequest'}  
    params = {  
        'type': 'uid',  
        'containerid': '231051_-_followers_-_{0}'.format(uid),
        'page': page  
    }  
    url = base_url + urlencode(params) 
    try:  
        response = requests.get(url, headers=headers)  
        if response.status_code == 200:  
#             with open('response.txt','a') as f:
#                 f.write(str(response.json()))
            return response.json()
    except requests.ConnectionError as e:  
        print('Error', e.args)   
        
def count_all(json):
    if json:
        total = json.get('data').get('cardlistInfo').get('total') #寻找数据中的关注量的总数
        
    return total

def parse_page(json):  
    if json:  
        items = json.get('data').get('cards') #拆分字典
        try :     #try语句，解决list溢出
            card_group = items[-1].get('card_group')#最后一组开始
        except IndexError:
            card_group = items[1].get('card_group')#字典中1位的数组内容
        except IndexError:
            card_group = items[0].get('card_group')#字典中0位的数组内容 ,这里缘于其构造问题，得先看item[1],再看itme[0],视具体情况而定，也可以-1
        weibo = {}
        i = 0
        while card_group[i].get('desc2'):
            name = card_group[i].get('user').get('screen_name')
            weibo['name'] = name
            weibo['fans_count'] = card_group[i].get('desc2')#粉丝数量
            i +=1
            try :#try语句，解决list溢出
                card_group[i].get('desc2')
            except IndexError:
                break
                
            yield weibo

def main():
    json = get_page(1)
    count = count_all(json)
    print("总共有{0}位关注者".format(count))
    num = int(count/20 + 1) #每一页粉丝爬取20个
    try :
        for page in range(1, num):  
            json = get_page(page)  
            results = parse_page(json)  
            for weibo in results:  
                with open('微博关注者粉丝量.csv','a') as f: #csv文件
                    zone = csv.writer(f)
                    zone.writerows([[weibo['name'],weibo['fans_count']]])
        print("爬取成功！")
    except IndexError as e:
        print("错误为" + str(e))#这里有个疑问，观察过很多微博博主，好友量实际并没有那么多，这里很容易造成列表溢出。
        pass
    
if __name__ == '__main__': 
    main()
